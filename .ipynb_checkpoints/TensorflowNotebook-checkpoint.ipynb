{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Cover Type (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "df = pd.read_csv(\"data/covtype.csv\")\n",
    "data = df[[\n",
    "    'Elevation',\n",
    "    'Aspect',\n",
    "    'Slope',\n",
    "    'Horizontal_Distance_To_Hydrology',\n",
    "    'Vertical_Distance_To_Hydrology',\n",
    "    'Horizontal_Distance_To_Roadways',\n",
    "    'Hillshade_9am',\n",
    "    'Hillshade_Noon',\n",
    "    'Hillshade_3pm',\n",
    "    'Horizontal_Distance_To_Fire_Points',\n",
    "    'Cover_Type'\n",
    "]].copy()\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.1)\n",
    "train_data_x = train_data.drop(\"Cover_Type\", axis=1)\n",
    "train_data_y = train_data[\"Cover_Type\"].copy() - 1\n",
    "\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5)\n",
    "val_data_x = val_data.drop(\"Cover_Type\", axis=1)\n",
    "val_data_y = val_data[\"Cover_Type\"].copy() - 1\n",
    "test_data_x = test_data.drop(\"Cover_Type\", axis=1)\n",
    "test_data_y = test_data[\"Cover_Type\"].copy() - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow model\n",
    "BATCH_SIZE = 128\n",
    "X = tf.placeholder(tf.float32, shape=(None, 10), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(BATCH_SIZE).repeat()\n",
    "itera = dataset.make_initializable_iterator()\n",
    "features, labels = itera.get_next()\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(\n",
    "        inputs=features,\n",
    "        units=256,\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    hidden2 = tf.layers.dense(\n",
    "        inputs=hidden1,\n",
    "        units=64,\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    hidden3 = tf.layers.dense(\n",
    "        inputs=hidden2,\n",
    "        units=16,\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=hidden3,\n",
    "        units=7,\n",
    "        activation=None\n",
    "    )\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=labels,\n",
    "        logits=logits\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    tf.print(\"Logits: \", logits, output_stream=sys.stdout)\n",
    "    tf.print(\"Labels: \", labels, output_stream=sys.stdout)\n",
    "    tf.print(\"Correct: \", correct, output_stream=sys.stdout)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch: 5, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 10, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 15, Loss: 1.205, Accuracy: 0.488\n",
      "Train - Epoch: 20, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 25, Loss: 1.205, Accuracy: 0.488\n",
      "Train - Epoch: 30, Loss: 1.205, Accuracy: 0.488\n",
      "Train - Epoch: 35, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 40, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 45, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 50, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 55, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 60, Loss: 1.206, Accuracy: 0.488\n",
      "Train - Epoch: 65, Loss: 1.205, Accuracy: 0.488\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1500\n",
    "n_batchs = train_data_x.shape[0] // BATCH_SIZE\n",
    "#n_bacths_validation = val_data_x.shape[0] // BATCH_SIZE\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    sess.run(itera.initializer, feed_dict={X: train_data_x.values, y: train_data_y.values})\n",
    "    for i in range(EPOCHS):\n",
    "        acc_total = 0\n",
    "        loss_total = 0\n",
    "        for _ in range(n_batchs):\n",
    "            _, loss_val, acc_val = sess.run([training_op, loss, accuracy])\n",
    "            acc_total += acc_val\n",
    "            loss_total += loss_val\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(\"Train - Epoch: {}, Loss: {:.3f}, Accuracy: {:.3f}\".format(i+1, loss_total/n_batchs, acc_total/n_batchs))\n",
    "    \n",
    "#     sess.run(iter.initializer, feed_dict={ x: val_data_x.values, y: val_data_y.values})\n",
    "#     acc_total_val = 0\n",
    "#     loss_total_val = 0\n",
    "#     for _ in range(n_bacths_validation):\n",
    "#         loss_valida, acc_valida = sess.run([loss, accuracy])\n",
    "#         acc_total_val += acc_valida\n",
    "#         loss_total_val += loss_valida\n",
    "#     print(\"Val - Epoch: {}, Loss: {:.3f}, Accuracy: {:.3f}\".format(i+1, loss_total_val, acc_total_val))\n",
    "    \n",
    "    save_path = saver.save(sess, \"model/final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera = dataset.make_one_shot_iterator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(itera.get_next())[0])\n",
    "            break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
